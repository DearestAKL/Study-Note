## 为什么GPU编程避免使用分支条件语句

​	GPU的设计目标是优化多线程吞吐量，即一定时间内有多少线程能够完成。GPU不关心单一线程执行的快慢与否(事实.上，GPU单线程要比CPU单线程慢很多)。因此，当前的**GPU把大量的芯片面积用于计算部件,取消分支预测和猜测执行**等复杂的又占芯片面积的微体系结构部件，这就**造成了流水线中可能存在分支开销**。当程序中分支条件越多时，带来的分支开销就越大。另外，GPU的执行方式与与CPU完全不一样，GPU线程一批一批(即一个warp或者wavefront)的执行。一批线程是完全同步执行的，不可继续划分前半批先执行后半批后执行。当一批线程中需要分支时(如， 前半批做加法，后半批做减法)，GPU先用一批执行加法，然后扔掉后半批的结果，再用同一批执行减法，然后扔掉前半批的结果。也就是说，这种情况下，GPU的分支执行时间等于if和else之和，而不是像CPU那样取决于if或者else的时间。

### 总结

- **GPU把大量的芯片面积用于计算部件，取消了分支预测和猜测执行等复杂结构部件。**
- **GPU一批线程是完全同步执行，GPU的分支执行时间等于if和else之和。**

